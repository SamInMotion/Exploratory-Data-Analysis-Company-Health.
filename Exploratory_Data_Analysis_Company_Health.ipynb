{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmghqvp7QXiK257EOtzP+U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tm-ui/Exploratory-Data-Analysis-Company-Health./blob/main/Exploratory_Data_Analysis_Company_Health.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning- Followed these Steps: Reindex the Questions: Ensure the questions are indexed from 1 to 75 to match the number of responses.Question indexing starts at 3 and ends at 78. Separate the Responses: Split the string of responses from the responses CSV into individual columns, each representing a response to a specific question. Correlate Responses with Questions: Align the responses to each question chronologically. Begin Analysis: Once data alignment is ensured, we proceed with the analysis."
      ],
      "metadata": {
        "id": "KEMK0gTug-AG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehfo1xpLr9eP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import uuid\n",
        "\n",
        "# 1. First, reindex the questions from 1 to 75 in the questions DataFrame.\n",
        "\n",
        "# Step 1: Load and Clean the Responses DataFrame\n",
        "\n",
        "# Load the responses DataFrame (anonymized file path)\n",
        "responses_df = pd.read_csv('/content/responses.csv')\n",
        "\n",
        "# List of valid responders (anonymized responder names)\n",
        "valid_responders = ['User_1', 'User_2', 'User_3', 'User_4', 'User_5', 'User_6']\n",
        "\n",
        "# Filter the DataFrame to keep only rows with valid responders\n",
        "cleaned_responses_df = responses_df[responses_df['ResponderName'].isin(valid_responders)]\n",
        "\n",
        "# Further filter out entries where 'ResponderName' is 'User_2' and 'Response' is empty\n",
        "cleaned_responses_df = cleaned_responses_df[~((cleaned_responses_df['ResponderName'] == 'User_2') & (cleaned_responses_df['Response'].isna()))]\n",
        "\n",
        "# Reset the index after filtering\n",
        "cleaned_responses_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Display the cleaned DataFrame\n",
        "print(\"Cleaned Responses DataFrame:\")\n",
        "print(cleaned_responses_df.head())\n",
        "\n",
        "# Step 2: Load and Reindex the Questions DataFrame\n",
        "\n",
        "# Load the questions DataFrame (anonymized file path)\n",
        "questions_df = pd.read_csv('/content/questions.csv')\n",
        "\n",
        "# Ensure questions are indexed from 1 to 76\n",
        "questions_df['question_index'] = range(1, 77)  # Corrected range for indexing\n",
        "\n",
        "# Display to check the reindexing\n",
        "print(\"\\nReindexed Questions DataFrame:\")\n",
        "print(questions_df[['question_index', 'q_text', 'q_khi']].head())\n",
        "\n",
        "# Step 3: Separate Responses into Individual Columns\n",
        "\n",
        "# Separate the responses string into individual responses\n",
        "responses_df_expanded = cleaned_responses_df['Response'].apply(lambda x: pd.Series(list(str(x)))).rename(columns=lambda x: f'Q{x+1}')\n",
        "\n",
        "# Anonymize email and timestamp columns\n",
        "cleaned_responses_df['ResponderEmail'] = 'email_redacted@example.com'\n",
        "cleaned_responses_df['Creation Date'] = 'date_redacted'\n",
        "cleaned_responses_df['Modified Date'] = 'date_redacted'\n",
        "\n",
        "# Combine with responder details\n",
        "combined_df = pd.concat([cleaned_responses_df[['ResponderName', 'ResponderEmail', 'Creation Date', 'Modified Date']], responses_df_expanded], axis=1)\n",
        "\n",
        "# Display to check the combined DataFrame\n",
        "print(\"\\nCombined DataFrame with Separated Responses:\")\n",
        "print(combined_df.head())\n",
        "\n",
        "# Step 4: Align Responses with Questions\n",
        "\n",
        "# Ensure correct alignment by renaming response columns to include question text\n",
        "response_columns = [col for col in combined_df.columns if col.startswith('Q')]\n",
        "question_texts = questions_df.set_index('question_index')['q_text'].to_dict()\n",
        "\n",
        "# Rename response columns to include question text\n",
        "combined_df.rename(columns={f'Q{i}': f'Q{i}: {question_texts[i]}' for i in range(1, 76)}, inplace=True)\n",
        "\n",
        "# Display the aligned DataFrame\n",
        "print(\"\\nAligned DataFrame with Question Texts:\")\n",
        "print(combined_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Save the anonymized combined DataFrame to CSV\n",
        "anonymized_combined_save_path = '/content/anonymized_combined_df.csv'\n",
        "combined_df.to_csv(anonymized_combined_save_path, index=False)\n",
        "\n",
        "# Save the anonymized cleaned responses DataFrame to CSV\n",
        "anonymized_responses_save_path = '/content/anonymized_cleaned_responses_df.csv'\n",
        "cleaned_responses_df.to_csv(anonymized_responses_save_path, index=False)\n",
        "\n",
        "# Notify user that the anonymized files have been saved\n",
        "print(f\"Anonymized Combined DataFrame saved to: {anonymized_combined_save_path}\")\n",
        "print(f\"Anonymized Cleaned Responses DataFrame saved to: {anonymized_responses_save_path}\")\n",
        "\n",
        "# Step 5: Calculating the number of non-missing responses for each user\n",
        "user_response_counts = cleaned_responses_df['Response'].apply(lambda x: len([char for char in str(x) if char not in [None, 'NaN', 'nan']]))\n",
        "\n",
        "# Calculating the average number of responses per user\n",
        "average_responses_per_user = user_response_counts.mean()\n",
        "\n",
        "# Display the calculated average\n",
        "print(f\"Average number of responses per user: {average_responses_per_user}\")\n"
      ],
      "metadata": {
        "id": "QTvGnVjJs0hR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Analysis are based on these questions:\n",
        "\n",
        " Which question got the most positive, negative, or maybe responses?\n",
        "Which category got the most positive, negative, or maybe responses?\n",
        "Which user gave the most positive, negative, or maybe responses?\n",
        "\n",
        "By following these steps:\n",
        "\n",
        "Calculate the Counts of Each Response Type (0, 1, ?) for Each Question:\n",
        "\n",
        "Determine which question has the highest counts for each response type.\n",
        "Calculate the Counts of Each Response Type for Each Category:\n",
        "\n",
        "Group the responses by category and calculate the counts of each response type.\n",
        "Calculate the Counts of Each Response Type for Each User:\n",
        "\n",
        "Group the responses by user and calculate the counts of each response time"
      ],
      "metadata": {
        "id": "mUT0pKVihNZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 6: Convert response columns to strings to avoid mixed type issues\n",
        "response_columns = [col for col in combined_df.columns if 'Q' in col]\n",
        "combined_df[response_columns] = combined_df[response_columns].astype(str)\n",
        "\n",
        "# Exclude Q76 from analysis since it has missing values for most users\n",
        "response_columns = [col for col in response_columns if col != 'Q76']\n",
        "\n",
        "# Step 7: Check for missing values in response columns after excluding Q76\n",
        "missing_values = combined_df[response_columns].isna().sum()\n",
        "print(\"\\nMissing Values in Response Columns After Excluding Q76:\")\n",
        "print(missing_values[missing_values > 0])\n",
        "\n",
        "# Step 8: Recalculate the distribution of response values ('0', '1', '?')\n",
        "response_counts = combined_df[response_columns].apply(pd.Series.value_counts).fillna(0)\n",
        "print(\"\\nResponse Value Counts:\")\n",
        "print(response_counts)\n",
        "\n",
        "# Step 9: Visualize response distribution by question\n",
        "plt.figure(figsize=(12, 8))\n",
        "response_counts.T.plot(kind='bar', stacked=True)\n",
        "plt.title('Response Distribution Across Questions')\n",
        "plt.xlabel('Questions')\n",
        "plt.ylabel('Count of Responses')\n",
        "plt.xticks(rotation=90)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Step 10: Identify the question with most positive, negative, and maybe responses\n",
        "most_positive_question = response_counts.loc['1'].idxmax()\n",
        "most_negative_question = response_counts.loc['0'].idxmax()\n",
        "most_maybe_question = response_counts.loc['?'].idxmax()\n",
        "\n",
        "# Display the questions with the highest response counts for each category\n",
        "print(f\"Question with most positive responses: {most_positive_question}\")\n",
        "print(f\"Question with most negative responses: {most_negative_question}\")\n",
        "print(f\"Question with most 'maybe' responses: {most_maybe_question}\")\n"
      ],
      "metadata": {
        "id": "k46zP_Hkae64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 11: Perform analysis on the aligned DataFrame (Q1 to Q75)\n",
        "\n",
        "# Calculate counts for each response type ('1', '0', and '?') for each question\n",
        "positive_counts = combined_df[response_columns].apply(lambda x: (x == '1').sum(), axis=0)\n",
        "negative_counts = combined_df[response_columns].apply(lambda x: (x == '0').sum(), axis=0)\n",
        "maybe_counts = combined_df[response_columns].apply(lambda x: (x == '?').sum(), axis=0)\n",
        "\n",
        "# Display the questions with the highest count of each response type\n",
        "print(f\"Question with most positive responses: {positive_counts.idxmax()}\")\n",
        "print(f\"Question with most negative responses: {negative_counts.idxmax()}\")\n",
        "print(f\"Question with most 'maybe' responses: {maybe_counts.idxmax()}\")\n"
      ],
      "metadata": {
        "id": "tE6e12BZauLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changed the color and sizes to clearly see the visualized correlations. (red for no, green for yes and grey for question mark(maybe)) Mixed Data Types: Some columns have mixed types (int64 and object), leading to errors during operations like sorting or counting. Missing Data: The last question (Q76) has missing values (NaN) for most users, and is excluded from analysis."
      ],
      "metadata": {
        "id": "Q_8Xlt5Ghfkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Step 12: Convert response columns to strings to avoid mixed type issues\n",
        "combined_df[response_columns] = combined_df[response_columns].astype(str)\n",
        "\n",
        "# Calculate the distribution of response values ('0', '1', '?')\n",
        "response_counts = combined_df[response_columns].apply(pd.Series.value_counts).fillna(0)\n",
        "\n",
        "# Define colors for the responses ('0' -> Red, '1' -> Green, '?' -> Grey)\n",
        "colors = {'0': 'red', '1': 'green', '?': 'grey'}\n",
        "\n",
        "# Step 13: Plot the response distribution with custom colors\n",
        "plt.figure(figsize=(12, 8))\n",
        "ax = response_counts.T.plot(kind='bar', stacked=True, color=[colors.get(x, '#333333') for x in response_counts.index])\n",
        "\n",
        "# Set plot titles and labels\n",
        "plt.title('Response Distribution Across Questions')\n",
        "plt.xlabel('Questions')\n",
        "plt.ylabel('Count of Responses')\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "# Add a legend for better clarity\n",
        "plt.legend(title='Responses', labels=['Negative (0)', 'Positive (1)', 'Maybe (?)'])\n",
        "\n",
        "# Save the plot as an image file\n",
        "output_image_path = '/content/response_distribution_questions.png'\n",
        "plt.savefig(output_image_path)\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Notify the user that the plot has been saved\n",
        "print(f\"Plot saved as an image at: {output_image_path}\")\n"
      ],
      "metadata": {
        "id": "RecH8nYna-BK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 14: Load the questions DataFrame and map questions to categories\n",
        "questions_df = pd.read_csv('/content/questions.csv')\n",
        "questions_df['question_index'] = range(1, 77)  # Ensure correct question indexing\n",
        "\n",
        "# Create a category map from the questions DataFrame\n",
        "category_map = questions_df.set_index('question_index')['q_khi'].to_dict()\n",
        "\n",
        "# Create a DataFrame to map responses to categories\n",
        "response_category_df = pd.DataFrame(index=response_columns)\n",
        "\n",
        "# Step 15: Map each question to its corresponding category\n",
        "response_category_df['Category'] = response_category_df.index.map(lambda x: category_map[int(x.split(':')[0][1:])])\n",
        "\n",
        "# Calculate the distribution of response values ('0', '1', '?') for each question\n",
        "response_counts = combined_df[response_columns].apply(pd.Series.value_counts).fillna(0)\n",
        "\n",
        "# Assign categories to the response counts DataFrame\n",
        "response_counts = response_counts.T\n",
        "response_counts['Category'] = response_counts.index.map(lambda x: category_map[int(x.split(':')[0][1:])])\n",
        "\n",
        "# Step 16: Visualize the response distribution grouped by categories\n",
        "categories = response_counts['Category'].unique()\n",
        "\n",
        "# Define custom colors for response types\n",
        "colors = {'0': 'red', '1': 'green', '?': 'grey'}\n",
        "\n",
        "# Create subplots for each category\n",
        "fig, axes = plt.subplots(nrows=len(categories), figsize=(14, 4 * len(categories)), sharex=True)\n",
        "\n",
        "for ax, category in zip(axes, categories):\n",
        "    # Filter data for the current category\n",
        "    category_data = response_counts[response_counts['Category'] == category].drop(columns='Category')\n",
        "\n",
        "    # Plot the response distribution for the current category using custom colors\n",
        "    category_data.plot(kind='bar', stacked=True, color=[colors.get(x, '#333333') for x in category_data.columns], ax=ax)\n",
        "\n",
        "    ax.set_title(f'Response Distribution for {category}')\n",
        "    ax.set_xlabel('Questions')\n",
        "    ax.set_ylabel('Count of Responses')\n",
        "    ax.legend(title='Responses', labels=['Negative (0)', 'Positive (1)', 'Maybe (?)'])\n",
        "\n",
        "# Step 17: Adjust the layout and save the plot as an image file\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the plot as an image for future reference\n",
        "output_image_path_category = '/content/response_distribution_categories(Khi).png'\n",
        "plt.savefig(output_image_path_category)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n",
        "# Notify the user where the image is saved\n",
        "print(f\"Plot of response distribution by categories saved as: {output_image_path_category}\")\n"
      ],
      "metadata": {
        "id": "yl9X59pObXTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 18: Analyze and visualize response distributions by user\n",
        "\n",
        "# Convert response columns to strings to avoid mixed type issues\n",
        "response_columns = [col for col in combined_df.columns if 'Q' in col]\n",
        "combined_df[response_columns] = combined_df[response_columns].astype(str)\n",
        "\n",
        "# Exclude Q76 from analysis since it has missing values for most users\n",
        "response_columns = [col for col in response_columns if col != 'Q76']\n",
        "\n",
        "# Define colors for the responses\n",
        "colors = {'0': 'red', '1': 'green', '?': 'grey'}\n",
        "\n",
        "# Get unique user names from the combined DataFrame\n",
        "users = combined_df['ResponderName'].unique()\n",
        "\n",
        "# Step 19: Create subplots for each user to visualize their response distribution\n",
        "fig, axes = plt.subplots(nrows=len(users), figsize=(14, 4 * len(users)), sharex=True)\n",
        "\n",
        "for ax, user in zip(axes, users):\n",
        "    # Filter responses for the current user\n",
        "    user_responses = combined_df[combined_df['ResponderName'] == user][response_columns]\n",
        "\n",
        "    # Calculate response counts for the user\n",
        "    user_counts = user_responses.apply(pd.Series.value_counts).fillna(0).T\n",
        "\n",
        "    # Plot the response distribution for the current user with custom colors\n",
        "    user_counts.plot(kind='bar', stacked=True, color=[colors.get(x, '#333333') for x in user_counts.columns], ax=ax)\n",
        "\n",
        "    ax.set_title(f'Response Distribution for {user}')\n",
        "    ax.set_xlabel('Questions')\n",
        "    ax.set_ylabel('Count of Responses')\n",
        "    ax.legend(title='Responses', labels=['Negative (0)', 'Positive (1)', 'Maybe (?)'])\n",
        "\n",
        "# Step 20: Adjust the layout and save the plot as an image file\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the plot as an image\n",
        "output_image_path_users = '/content/response_distribution_users.png'\n",
        "plt.savefig(output_image_path_users)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n",
        "# Notify the user where the image is saved\n",
        "print(f\"Plot of response distribution by users saved as: {output_image_path_users}\")\n"
      ],
      "metadata": {
        "id": "tyP9BOO2brdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 21: Visualize the response distribution for each user\n",
        "\n",
        "# Convert response columns to strings to avoid mixed type issues\n",
        "response_columns = [col for col in combined_df.columns if 'Q' in col]\n",
        "combined_df[response_columns] = combined_df[response_columns].astype(str)\n",
        "\n",
        "# Exclude Q76 from analysis since it has missing values for most users\n",
        "response_columns = [col for col in response_columns if col != 'Q76']\n",
        "\n",
        "# Define colors for the response types\n",
        "colors = {'0': 'red', '1': 'green', '?': 'grey'}\n",
        "\n",
        "# Get the unique responder names from the DataFrame\n",
        "users = combined_df['ResponderName'].unique()\n",
        "\n",
        "# Step 22: Create subplots to visualize each user's response distribution\n",
        "fig, axes = plt.subplots(nrows=len(users), figsize=(14, 4 * len(users)), sharex=True)\n",
        "\n",
        "# Iterate over each user to generate a separate plot\n",
        "for ax, user in zip(axes, users):\n",
        "    # Filter the responses for the current user\n",
        "    user_responses = combined_df[combined_df['ResponderName'] == user][response_columns]\n",
        "\n",
        "    # Calculate response counts for each question (0, 1, ?)\n",
        "    user_counts = user_responses.apply(pd.Series.value_counts).fillna(0).T\n",
        "\n",
        "    # Plot the response distribution for the current user\n",
        "    user_counts.plot(kind='bar', stacked=True,\n",
        "                     color=[colors.get(x, '#333333') for x in user_counts.columns], ax=ax)\n",
        "\n",
        "    # Set titles and labels\n",
        "    ax.set_title(f'Response Distribution for {user}')\n",
        "    ax.set_xlabel('Questions')\n",
        "    ax.set_ylabel('Count of Responses')\n",
        "    ax.legend(title='Responses', labels=['Negative (0)', 'Positive (1)', 'Maybe (?)'])\n",
        "\n",
        "# Step 23: Layout adjustments and saving the plot\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the user response distribution plot as an image\n",
        "output_image_path_users = '/content/response_distribution_users.png'\n",
        "plt.savefig(output_image_path_users)\n",
        "\n",
        "# Display the plot in the notebook\n",
        "plt.show()\n",
        "\n",
        "# Notify where the plot image has been saved\n",
        "print(f\"Response distribution plot by user saved at: {output_image_path_users}\")\n"
      ],
      "metadata": {
        "id": "M3kesiTNeUBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 24: Map questions to their respective categories using the questions DataFrame\n",
        "questions_df = pd.read_csv('/content/questions.csv.csv')\n",
        "\n",
        "# Ensure the questions are indexed correctly and map them to categories\n",
        "questions_df['question_index'] = range(1, 77)\n",
        "category_map = questions_df.set_index('question_index')['q_khi'].to_dict()\n",
        "\n",
        "# Step 25: Calculate response counts and assign categories\n",
        "# Count occurrences of each response value ('0', '1', '?') for every question\n",
        "response_counts = combined_df[response_columns].apply(pd.Series.value_counts).fillna(0).T\n",
        "\n",
        "# Map each question to its category based on 'q_khi' and add as a column in response_counts\n",
        "response_counts['Category'] = response_counts.index.map(lambda x: category_map[int(x.split(':')[0][1:])])\n",
        "\n",
        "# Step 26: Aggregate the response counts by category\n",
        "category_totals = response_counts.groupby('Category').sum()\n",
        "\n",
        "# Step 27: Generate pie charts for each category's response distribution\n",
        "for category in category_totals.index:\n",
        "    # Create a pie chart for each category\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.pie(\n",
        "        category_totals.loc[category],\n",
        "        labels=['Negative (0)', 'Positive (1)', 'Maybe (?)'],\n",
        "        autopct='%1.1f%%',\n",
        "        colors=['red', 'green', 'grey'],\n",
        "        startangle=140\n",
        "    )\n",
        "    plt.title(f'Response Distribution for {category}')\n",
        "    plt.axis('equal')  # Ensures the pie chart is a perfect circle\n",
        "\n",
        "    # Display the pie chart\n",
        "    plt.show()\n",
        "\n",
        "    # Save the pie chart to a file\n",
        "    output_image_path_pie = f'/content/response_distribution_{category}_pie_chart.png'\n",
        "    plt.savefig(output_image_path_pie)\n",
        "\n",
        "    # Notify where the pie chart has been saved\n",
        "    print(f\"Pie chart for {category} saved at: {output_image_path_pie}\")\n"
      ],
      "metadata": {
        "id": "IYfrdA_oepHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 28: Convert data from the JSON-like structure into a DataFrame for easier manipulation\n",
        "data = [\n",
        "    {\"ResponderName\": \"Theodor\", \"ResponderEmail\": \"\", \"Creation Date\": \"Aug 20, 2024 3:45 am\", \"Modified Date\": \"Aug 20, 2024 3:46 am\",\n",
        "    \"Q1: I understand how my work contributes to Hovedkvarteret's overall strategy.\": \"1\",\n",
        "    \"Q2: Hovedkvarteret's strategy is clearly communicated and consistently reinforced.\": \"1\",\n",
        "    \"Q3: I believe Hovedkvarteret's strategy positions us well in the tech consulting market.\": \"0\",\n",
        "    \"Q4: nan\": \"0\", \"Q5: nan\": \"0\", \"Q6: nan\": \"?\", \"Q7: nan\": \"?\", \"Q8: nan\": \"?\",\n",
        "    \"Q9: nan\": \"1\", \"Q10: nan\": \"1\", \"Q11: nan\": \"1\", \"Q12: Hovedkvarteret can quickly adapt to changes in the tech consulting market.\": \"1\",\n",
        "    \"Q13: We effectively balance current client needs with long-term innovation.\": \"1\",\n",
        "    # More responses go here...\n",
        "    }\n",
        "]\n",
        "\n",
        "# Convert the data into a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Step 29: Select only columns that start with 'Q' as response columns\n",
        "response_columns = [col for col in df.columns if col.startswith('Q')]\n",
        "\n",
        "# Flatten the response columns into a single series for counting occurrences\n",
        "all_responses = df[response_columns].stack()\n",
        "\n",
        "# Count occurrences of each response type ('1', '0', '?')\n",
        "response_counts = all_responses.value_counts()\n",
        "\n",
        "# Step 30: Prepare data for the pie chart\n",
        "labels = ['Positive (1)', 'Negative (0)', 'Maybe (?)']\n",
        "sizes = [response_counts.get('1', 0), response_counts.get('0', 0), response_counts.get('?', 0)]\n",
        "colors = ['green', 'red', 'grey']\n",
        "\n",
        "# Step 31: Plot the pie chart for overall response distribution\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(sizes, labels=labels, autopct='%1.1f%%', colors=colors, startangle=140)\n",
        "plt.title('Overall Distribution of Positive, Negative, and Maybe Responses')\n",
        "plt.axis('equal')  # Ensures that the pie chart is a circle\n",
        "plt.show()\n",
        "\n",
        "# Step 32: Save the pie chart as an image file\n",
        "plt.savefig('Overall Distribution Pie.png')\n",
        "\n",
        "# Notify where the file is saved\n",
        "print(\"Overall distribution pie chart saved as 'Overall Distribution Pie.png'\")\n"
      ],
      "metadata": {
        "id": "SIKSTPewe8nQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Load the questions DataFrame and map questions to categories\n",
        "questions_df = pd.read_csv('/content/questions.csv.csv')\n",
        "questions_df['question_index'] = range(1, 77)\n",
        "category_map = questions_df.set_index('question_index')['q_khi'].to_dict()\n",
        "\n",
        "# Step 2: Extract response columns from the combined DataFrame\n",
        "response_columns = [col for col in combined_df.columns if 'Q' in col]\n",
        "\n",
        "# Step 3: Exclude Q76 from analysis if it has missing values for most users\n",
        "response_columns = [col for col in response_columns if col != 'Q76']\n",
        "\n",
        "# Step 4: Calculate the distribution of response values ('0', '1', '?') for each question\n",
        "response_counts = combined_df[response_columns].apply(pd.Series.value_counts).fillna(0).T\n",
        "\n",
        "# Step 5: Assign categories to each question based on the question index\n",
        "response_counts['Category'] = response_counts.index.map(lambda x: category_map[int(x.split(':')[0][1:])])\n",
        "\n",
        "# Step 6: Define colors for the responses\n",
        "colors = {'0': 'red', '1': 'green', '?': 'grey'}\n",
        "\n",
        "# Step 7: Iterate over each category to create a separate bar chart for each\n",
        "categories = response_counts['Category'].unique()\n",
        "\n",
        "for category in categories:\n",
        "    # Filter data for the current category\n",
        "    category_data = response_counts[response_counts['Category'] == category]\n",
        "\n",
        "    # Prepare the data for plotting\n",
        "    n_questions = len(category_data)  # Number of questions in the category\n",
        "    bar_width = 0.2  # Width of each bar\n",
        "    index = np.arange(n_questions)  # Index positions for questions\n",
        "\n",
        "    # Initialize the plot for the current category\n",
        "    fig, ax = plt.subplots(figsize=(14, 8))  # Adjusted figure size for clarity\n",
        "\n",
        "    # Plot each response type within the current category\n",
        "    for i, response_type in enumerate(['0', '1', '?']):\n",
        "        ax.bar(index + i * bar_width, category_data[response_type], bar_width,\n",
        "               label=response_type, color=colors[response_type])\n",
        "\n",
        "    # Customize the x-axis to show question keys\n",
        "    ax.set_xticks(index + bar_width)\n",
        "    ax.set_xticklabels([f'Q{i+1}' for i in range(n_questions)], rotation=0, ha='center')\n",
        "    ax.set_xlabel('Questions (Keys)')\n",
        "    ax.set_ylabel('Count of Responses')\n",
        "    ax.set_title(f'Response Distribution for {category}')\n",
        "\n",
        "    # Adjust y-axis and remove default ticks for clarity\n",
        "    ax.legend(title='Response Type')\n",
        "\n",
        "    # Prepare full question texts for display under the plot\n",
        "    full_question_texts = [questions_df.loc[int(q.split(':')[0][1:])-1, 'q_text'] for q in category_data.index]\n",
        "\n",
        "    # Display full questions under the plot\n",
        "    plt.figtext(0.5, -0.25, '\\n'.join([f\"{f'Q{i+1}'}: {text}\" for i, text in enumerate(full_question_texts)]),\n",
        "                wrap=True, horizontalalignment='center', fontsize=10, ha='center')\n",
        "\n",
        "    # Save the plot as an image\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(bottom=0.35)  # Adjust bottom margin for question texts\n",
        "    plt.savefig(f'response_distribution_{category}.png', bbox_inches='tight')  # Ensures everything is included in the saved file\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "QTeNIQ_qfR78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mvZeQXvkg8KL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Step 1: Load the questions DataFrame and map questions to categories\n",
        "questions_df = pd.read_csv('/content/questions.csv')\n",
        "questions_df['question_index'] = range(1, 77)\n",
        "category_map = questions_df.set_index('question_index')['q_khi'].to_dict()\n",
        "\n",
        "# Step 2: Extract response columns from the combined DataFrame\n",
        "response_columns = [col for col in combined_df.columns if 'Q' in col]\n",
        "\n",
        "# Step 3: Exclude Q76 from analysis if it has missing values for most users\n",
        "response_columns = [col for col in response_columns if col != 'Q76']\n",
        "\n",
        "# Step 4: Calculate the distribution of response values ('0', '1', '?') for each question\n",
        "response_counts = combined_df[response_columns].apply(pd.Series.value_counts).fillna(0).T\n",
        "\n",
        "# Step 5: Assign categories to each question based on the question index\n",
        "response_counts['Category'] = response_counts.index.map(lambda x: category_map[int(x.split(':')[0][1:])])\n",
        "\n",
        "# Step 6: Define colors for the responses\n",
        "colors = {'0': 'red', '1': 'green', '?': 'grey'}\n",
        "\n",
        "# Step 7: Iterate over each category to create a separate bar chart for each\n",
        "categories = response_counts['Category'].unique()\n",
        "\n",
        "for category in categories:\n",
        "    # Filter data for the current category\n",
        "    category_data = response_counts[response_counts['Category'] == category]\n",
        "\n",
        "    # Prepare the data for plotting\n",
        "    n_questions = len(category_data)  # Number of questions in the category\n",
        "    bar_width = 0.2  # Width of each bar\n",
        "    index = np.arange(n_questions)  # Index positions for questions\n",
        "\n",
        "    # Initialize the plot for the current category\n",
        "    fig, ax = plt.subplots(figsize=(14, 8))  # Adjusted figure size for clarity\n",
        "\n",
        "    # Plot each response type within the current category\n",
        "    for i, response_type in enumerate(['0', '1', '?']):\n",
        "        ax.bar(index + i * bar_width, category_data[response_type], bar_width,\n",
        "               label=response_type, color=colors[response_type])\n",
        "\n",
        "    # Customize the x-axis to show question keys\n",
        "    ax.set_xticks(index + bar_width)\n",
        "    ax.set_xticklabels([f'Q{i+1}' for i in range(n_questions)], rotation=0, ha='center')\n",
        "    ax.set_xlabel('Questions (Keys)')\n",
        "    ax.set_ylabel('Count of Responses')\n",
        "    ax.set_title(f'Response Distribution for {category}')\n",
        "\n",
        "    # Adjust y-axis and remove default ticks for clarity\n",
        "    ax.legend(title='Response Type')\n",
        "\n",
        "    # Prepare full question texts for display under the plot\n",
        "    full_question_texts = [questions_df.loc[int(q.split(':')[0][1:])-1, 'q_text'] for q in category_data.index]\n",
        "\n",
        "    # Display full questions under the plot\n",
        "    plt.figtext(0.5, -0.25, '\\n'.join([f\"{f'Q{i+1}: '}{full_question_texts[i]}\" for i in range(n_questions)]), wrap=True, horizontalalignment='center', fontsize=12)\n",
        "\n",
        "    # Adjust layout and show plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "NGXbXUadf_9A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}